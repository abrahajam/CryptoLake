.PHONY: help up down down-clean logs status spark-shell kafka-topics

help: ## Mostrar esta ayuda
	@grep -E '^[a-zA-Z_-]+:.*?## .*$$' $(MAKEFILE_LIST) | sort | \
	awk 'BEGIN {FS = ":.*?## "}; {printf "\033[36m%-20s\033[0m %s\n", $$1, $$2}'

up: ## Arrancar todos los servicios
	@echo "üöÄ Arrancando CryptoLake..."
	docker compose up -d --build
	@echo ""
	@echo "‚è≥ Esperando a que los servicios est√©n listos (esto tarda ~60s la primera vez)..."
	@sleep 30
	@echo ""
	@echo "‚úÖ CryptoLake est√° corriendo!"
	@echo ""
	@echo "üìä Servicios disponibles:"
	@echo "   MinIO Console:   http://localhost:9001  (user: cryptolake / pass: cryptolake123)"
	@echo "   Kafka UI:        http://localhost:8084"
	@echo "   Spark UI:        http://localhost:8082"
	@echo "   Airflow:         http://localhost:8083  (user: admin / pass: admin)"
	@echo "   Iceberg Catalog: http://localhost:8181"
	@echo ""

down: ## Parar todos los servicios (conserva datos)
	docker compose down

down-clean: ## Parar y BORRAR todos los datos
	docker compose down -v
	@echo "üóëÔ∏è  Todos los volumes eliminados"

logs: ## Ver logs de todos los servicios
	docker compose logs -f

logs-kafka: ## Ver logs solo de Kafka
	docker compose logs -f kafka

logs-spark: ## Ver logs solo de Spark
	docker compose logs -f spark-master spark-worker

status: ## Ver estado de los servicios
	docker compose ps

spark-shell: ## Abrir consola PySpark interactiva
	docker exec -it cryptolake-spark-master \
    		/opt/spark/bin/pyspark

kafka-topics: ## Listar topics de Kafka
docker exec cryptolake-kafka \
    kafka-topics --bootstrap-server localhost:29092 --list

kafka-create-topics: ## Crear los topics necesarios
	docker exec cryptolake-kafka \
    		kafka-topics --bootstrap-server localhost:29092 \
    		--create --topic prices.realtime \
    		--partitions 3 --replication-factor 1 \
    		--config retention.ms=86400000
@echo "‚úÖ Topic 'prices.realtime' creado (retenci√≥n: 24h, 3 particiones)"

kafka-describe: ## Describir el topic de precios
	docker exec cryptolake-kafka \
    		kafka-topics --bootstrap-server localhost:29092 \
    		--describe --topic prices.realtime

bronze-load: ## Cargar datos de APIs a Bronze
	docker exec cryptolake-spark-master \
	    /opt/spark/bin/spark-submit \
	    /opt/spark/work/src/processing/batch/api_to_bronze.py

silver-transform: ## Transformar Bronze ‚Üí Silver
	docker exec cryptolake-spark-master \
	    /opt/spark/bin/spark-submit \
	    /opt/spark/work/src/processing/batch/bronze_to_silver.py

gold-transform: ## Transformar Silver ‚Üí Gold
	docker exec cryptolake-spark-master \
	    /opt/spark/bin/spark-submit \
	    /opt/spark/work/src/processing/batch/silver_to_gold.py

pipeline: ## Ejecutar pipeline completo: Bronze ‚Üí Silver ‚Üí Gold
	@echo "üöÄ Ejecutando pipeline completo..."
	$(MAKE) bronze-load
	$(MAKE) silver-transform
	$(MAKE) gold-transform
	@echo "‚úÖ Pipeline completado!"